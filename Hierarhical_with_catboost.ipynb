{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd0e10b6",
   "metadata": {},
   "source": [
    "## Демонстрация иерархического классификатора с использованием CatBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3072bcb",
   "metadata": {},
   "source": [
    "Импортируем необходимые библиотеки и модули, в том числе, модули мпровизированной HierarhicalLibrary, в которых содержатся необходимые для работы иерархического классификатора классы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3a25f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import tqdm\n",
    "\n",
    "from HierarhicalLibrary import Classifier, CategoryTree, TextProcessor\n",
    "from HierarhicalLibrary.Encoders import LdaEncoder, NavecEncoder, FasttextEncoder, BertEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ed4d20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1\n",
    "\n",
    "# Method for increasing the weight of the first words of title\n",
    "def word_pyramid(string: str, min_n_words: int, max_n_words: int) -> list:\n",
    "    result = []\n",
    "    split = string.split(' ')\n",
    "    for i in range(min_n_words, max_n_words+1):\n",
    "        result += split[:i]\n",
    "    return ' '.join(result)\n",
    "\n",
    "def prepare_data(full_train_data: pd.DataFrame, seed: int, valid_size: int):\n",
    "    data_full = full_train_data.sample(frac=1, random_state=seed).copy()\n",
    "    data_full.drop(['rating', 'feedback_quantity'], axis=1, inplace=True)\n",
    "    data_full.title = data_full.title.astype('string')\n",
    "    data_full.short_description = data_full.short_description.astype('string')\n",
    "    data_full.fillna(value='', inplace=True)\n",
    "    data_full.name_value_characteristics = data_full.name_value_characteristics.astype('string')\n",
    "    data_full = data_full.assign(Document=[str(x) + ' ' + str(y) + ' ' + str(z) + ' ' + word_pyramid(x, 2, 3) for x, y, z in zip(data_full['title'], data_full['short_description'], data_full['name_value_characteristics'])])\n",
    "    data_full.drop(['title', 'short_description', 'name_value_characteristics'], axis=1, inplace=True)\n",
    "    data_full.Document = data_full.Document.astype('string')\n",
    "\n",
    "    data = data_full[:-valid_size].reset_index(drop=True)\n",
    "    data_valid = data_full[-valid_size:].reset_index(drop=True)\n",
    "    return data, data_valid\n",
    "\n",
    "def set_seeds(seed: int):  \n",
    "    np.random.seed(seed)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e914af5",
   "metadata": {},
   "source": [
    "Загружаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f64d533f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_tree_df = pd.read_csv('categories_tree.csv', index_col=0)\n",
    "full_train_data = pd.read_parquet('train.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a37cc8",
   "metadata": {},
   "source": [
    "Подготавливаем полный, тренировочный и валидационный датасеты:\n",
    "перемешиваем данные в фрейме,\n",
    "удаляем колонки рейтинга и кол-ва отзывов,\n",
    "корректируем типы данных колонок,\n",
    "заполняем пропущенные значения,\n",
    "текст из колонок 'title', 'short_description' и 'name_value_characteristics' объединяем в колонку \"Document\", добавляем первые слова из колонки 'title', чтобы увеличить их вес."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "337cfb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seeds(SEED)\n",
    "data, data_valid = prepare_data(full_train_data, seed=SEED, valid_size=4000)\n",
    "data = data[:50000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c4375a",
   "metadata": {},
   "source": [
    "Для ускорения расчетов, оставим только 50000 записей, иначе, считать будет долго."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bc02e72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>Document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1181186</td>\n",
       "      <td>12350</td>\n",
       "      <td>Маска Masil для объёма волос 8ml /Корейская ко...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>304936</td>\n",
       "      <td>12917</td>\n",
       "      <td>Силиконовый дорожный контейнер футляр чехол дл...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>816714</td>\n",
       "      <td>14125</td>\n",
       "      <td>Тканевая маска для лица с муцином улитки, 100%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1437391</td>\n",
       "      <td>11574</td>\n",
       "      <td>Браслеты из бисера Браслеты из бисера.  Брасле...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1234938</td>\n",
       "      <td>12761</td>\n",
       "      <td>Бальзам HAUTE COUTURE LUXURY BLOND для блондир...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>1291099</td>\n",
       "      <td>12488</td>\n",
       "      <td>Комплект постельного белья Считалочка, 1.5 сп,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>992089</td>\n",
       "      <td>13816</td>\n",
       "      <td>Патчи гля глаз кружевные LOVE  Beauty Fox с му...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>529715</td>\n",
       "      <td>13613</td>\n",
       "      <td>Пресс для чеснока MODERNO, прорезиненная ручка...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>750317</td>\n",
       "      <td>12228</td>\n",
       "      <td>Косметичка полиэстер/ПВХ розовая 19,5*11,5*11,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>880725</td>\n",
       "      <td>13408</td>\n",
       "      <td>Универсальное закаленное защитное стекло для i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  category_id                                           Document\n",
       "0      1181186        12350  Маска Masil для объёма волос 8ml /Корейская ко...\n",
       "1       304936        12917  Силиконовый дорожный контейнер футляр чехол дл...\n",
       "2       816714        14125  Тканевая маска для лица с муцином улитки, 100%...\n",
       "3      1437391        11574  Браслеты из бисера Браслеты из бисера.  Брасле...\n",
       "4      1234938        12761  Бальзам HAUTE COUTURE LUXURY BLOND для блондир...\n",
       "...        ...          ...                                                ...\n",
       "49995  1291099        12488  Комплект постельного белья Считалочка, 1.5 сп,...\n",
       "49996   992089        13816  Патчи гля глаз кружевные LOVE  Beauty Fox с му...\n",
       "49997   529715        13613  Пресс для чеснока MODERNO, прорезиненная ручка...\n",
       "49998   750317        12228  Косметичка полиэстер/ПВХ розовая 19,5*11,5*11,...\n",
       "49999   880725        13408  Универсальное закаленное защитное стекло для i...\n",
       "\n",
       "[50000 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b776fe0",
   "metadata": {},
   "source": [
    "### Text Processor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83f9673",
   "metadata": {},
   "source": [
    "Инициализируем объект энкодера (это класс, который управляет расчетами векторов скрытых представлений текстов, \"эмбеддингов\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5f70743",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_processor = TextProcessor(\n",
    "    add_stop_words=[',', '.', '', '|', ':', '\"', '/', ')', '(', 'a', 'х', '(:', '):', ':(', ':)', 'и']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca80ba2",
   "metadata": {},
   "source": [
    "Следующий код читает документы из датафрейма, выполняет токенизацию и лемматизацию средствами пакета natasha, затем, сохраняет леммы в собственную переменную Encoder.texts. Лемматизация выполняется достаточно долго, поэтому сохраняем данные на диск:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "554e02ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lemmatize: 100%|██████████| 50000/50000 [08:04<00:00, 103.22it/s]\n"
     ]
    }
   ],
   "source": [
    "text_processor.lemmatize_data(data, document_col='Document', id_col='id')\n",
    "text_processor.save_lemms_data('50000_set_lemm', directory='Hierarhical_with_catboost')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7578cf0c",
   "metadata": {},
   "source": [
    "Загружаем леммы с диска:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0436323f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_processor.load_lemms_data('50000_set_lemm', directory='Hierarhical_with_catboost')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90461f3",
   "metadata": {},
   "source": [
    "#### Энкодер на базе модели LDA gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d61d3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_encoder = LdaEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d440709",
   "metadata": {},
   "source": [
    "Выполняем тренировку LDA модели gensim (скажем, на 16 тем, чтобы побыстрее работало) и сразу сохраняем на диск, модель тренируется долго:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65886dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_encoder.fit(texts=text_processor.texts, num_topics=32, passes=5, iterations=2)\n",
    "lda_encoder.save_model('50000_set_model_32', directory='Hierarhical_with_catboost')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18cc08e",
   "metadata": {},
   "source": [
    "Загружаем модель с диска:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdc3946d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_encoder.load_model('50000_set_model_32', directory='Hierarhical_with_catboost')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697dc80c",
   "metadata": {},
   "source": [
    "Размерность эмбеддинга lda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e00c5448",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_encoder.transform([['foo']]).shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36dc30d6",
   "metadata": {},
   "source": [
    "#### Энкодер на базе модели navec\n",
    "параметр экспоненциального взвешивания эмбеддингов alpha=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "555adcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nevec_encoder = NavecEncoder(alpha=0.2, dim=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22620ecd",
   "metadata": {},
   "source": [
    "Загружаем обученную модель navec (скачана из родного репозитория)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5d4dca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nevec_encoder.load_model('navec_hudlit_v1_12B_500K_300d_100q.tar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2694bf",
   "metadata": {},
   "source": [
    "В случае необходимости, считаем и сохраняем матрицу снижения размерности эмбеддингов word2vec (например, на 128 векторов)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe17c48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nevec_encoder.calc_pca(texts=text_processor.texts, sample_size=10000)\n",
    "nevec_encoder.save_pca('PCA_navec.pickle', directory='Hierarhical_with_catboost')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b005e3",
   "metadata": {},
   "source": [
    "Загружаем матрицу для понижения размерности word2vec эмбеддингов (понижение размерности выполнено для увеличения производительности, если есть желание отключить понижение размерности - можно просто не указывать параметр dim или присвоить ему значение nevec_encoder.dim=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d32e060",
   "metadata": {},
   "outputs": [],
   "source": [
    "nevec_encoder.load_pca('PCA_navec.pickle', directory='Hierarhical_with_catboost')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45209929",
   "metadata": {},
   "source": [
    "Размерность эмбеддинга navec:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0160f356",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nevec_encoder.transform([['foo']]).shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411d071b",
   "metadata": {},
   "source": [
    "#### Расчёт составных эмбеддингов документов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94679a82",
   "metadata": {},
   "source": [
    "Используя встроенный метод энкодера, формируем словарь эмбеддингов товаров вида {good_id(int) : embedding(np.array)}. Передаем интересующие нас функции - энкодеры LDA и Word2vec. Параметр экспоненциального взвешивания эмбеддингов word2vec, alpha=0.25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10f17cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders=[lda_encoder, nevec_encoder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3424aa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dict = text_processor.make_embeddings_dict(encoders=encoders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b7e94c",
   "metadata": {},
   "source": [
    "Сохраняем словарь эмбеддингов при необходимости - загружаем сохранённый:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4887a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(Path(\".\").parent, 'Hierarhical_with_catboost', '50000_set_embs_dict.pickle')\n",
    "with open(path, 'wb') as f:\n",
    "    pickle.dump(embeddings_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4341cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(Path(\".\").parent, 'Hierarhical_with_catboost', '50000_set_embs_dict.pickle')\n",
    "with open(path, 'rb') as f:\n",
    "    embeddings_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671ccb16",
   "metadata": {},
   "source": [
    "### Дерево каталога"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d07d857",
   "metadata": {},
   "source": [
    "Инициализируем дерево каталога - CategoryTree() - это класс, который хранит все узлы, необходимую информацию для обучения, а также реализует алгоритмы заполнения дерева, обхода при инференсе для определения категории товара. \n",
    "Добавляем узлы из таблицы categories_tree.csv, затем, добавляем товары из тренировочной выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a8afb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_tree = CategoryTree()\n",
    "cat_tree.add_nodes_from_df(cat_tree_df, parent_id_col='parent_id', title_col='title')\n",
    "cat_tree.add_goods_from_df(data, category_id_col='category_id', good_id_col='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dda3fd",
   "metadata": {},
   "source": [
    "Записываем эмбеддинги в дерево каталогов (производится расчет эмбеддингов узлов как усреднённых эмбеддингов документов, попавших в каждый узел):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf8b3a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_tree.update_embeddings(embeddings_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933296a9",
   "metadata": {},
   "source": [
    "Примешиваем к эмбеддингам узлов эмбеддинги их собственных описаний."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0211f730",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cat_tree.mix_in_description_embs(lambda titles: text_processor.get_embeddings(titles, encoders=encoders), weight=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be436986",
   "metadata": {},
   "source": [
    "### Классификатор"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29aef372",
   "metadata": {},
   "source": [
    "Инициализируем объект классификатора - он управляет процессом получения вероятностей принадлежности товара к узлу (predict_proba). после этого, формируем массив-датасет для тренировки глобального классификатора, сохраняем его на диск (так как памяти массив занимает очень много, можно удалить его из оперативной памяти, потом снова загрузить с диска при необходимости)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "519716db",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Classifier(catboost_parameters={'loss_function': 'Logloss',\n",
    "                                    'iterations': 30,\n",
    "                                    'depth': 9,\n",
    "                                    'rsm': 1.0,\n",
    "                                    'random_seed': 1,\n",
    "                                    'learning_rate': 0.7\n",
    "                                    }, tol=0.03, max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a7d70f5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classifier.calc_global_train_array(embeddings_dict, cat_tree)\n",
    "classifier.save_global_train_array('50000_set_arr', directory='Hierarhical_with_catboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2d1bedb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.load_global_train_array('50000_set_arr', directory='Hierarhical_with_catboost')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69198f90",
   "metadata": {},
   "source": [
    "На сформированном датасете обучаем глобальный классификатор и сохраняем его. Массив больше не нужен."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b1befae",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit_global_classifier()\n",
    "classifier.save_global_classifier('50000_set_CatBoost.cbm', directory='Hierarhical_with_catboost')\n",
    "classifier.delete_global_train_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "929a2659",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.load_global_classifier('50000_set_CatBoost.cbm', directory='Hierarhical_with_catboost')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f037fe",
   "metadata": {},
   "source": [
    "Обучаем локальные веса (модель логистической регрессии в каждом из узлов дерева). Сохраняем дерево (так как считается очень долго). При необходимости - загружаем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "13553b09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3370/3370 [1:22:01<00:00,  1.46s/it]  \n"
     ]
    }
   ],
   "source": [
    "cat_tree.fit_local_weights(classifier, embeddings_dict, C=0.05, reg_count_power=0.5, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d3c028",
   "metadata": {},
   "source": [
    "Сохраняем, и при необходимости, загружаем дерево с рассчитанными весами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b961f9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_tree.save_tree('50000_set_tree.pickle', directory='Hierarhical_with_catboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2204b42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_tree.load_tree('50000_set_tree.pickle', directory='Hierarhical_with_catboost')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847914e3",
   "metadata": {},
   "source": [
    "### Тестирование модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0775bb3",
   "metadata": {},
   "source": [
    "#### Тестирование на трейне"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da40d51",
   "metadata": {},
   "source": [
    "Формируем массив эмбеддингов для тестирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0b8d6397",
   "metadata": {},
   "outputs": [],
   "source": [
    "begin_example = 0\n",
    "end_example = 3000\n",
    "train_documents = data.Document.tolist()[begin_example:end_example]\n",
    "train_target = data.category_id.tolist()[begin_example:end_example]\n",
    "embs = text_processor.get_embeddings(train_documents, encoders=encoders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc21d0fe",
   "metadata": {},
   "source": [
    "Выполняем поиск категорий по каталогу для каждого тестового примера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3a07cf12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [25:28<00:00,  1.96it/s]\n"
     ]
    }
   ],
   "source": [
    "pred_leafs = []\n",
    "for i in tqdm.tqdm(range(len(embs)), total=len(embs)):\n",
    "    pred_leafs.append(cat_tree.choose_leaf(classifier = classifier, good_embedding=embs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3672349f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set hF1=0.749\n"
     ]
    }
   ],
   "source": [
    "print(f'Train set hF1={cat_tree.hF1_score(train_target, pred_leafs):.3f}') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459b643a",
   "metadata": {},
   "source": [
    "#### Тестирование на отложенной выборке"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbad7a60",
   "metadata": {},
   "source": [
    "Формируем массив эмбеддингов для тестирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6e962267",
   "metadata": {},
   "outputs": [],
   "source": [
    "begin_example = 0\n",
    "end_example = 4000\n",
    "valid_documents = data_valid.Document.tolist()[begin_example:end_example]\n",
    "valid_target = data_valid.category_id.tolist()[begin_example:end_example]\n",
    "embs_valid = text_processor.get_embeddings(valid_documents, encoders=encoders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b936e16",
   "metadata": {},
   "source": [
    "Выполняем поиск категорий по каталогу для каждого тестового примера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "44eeae03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [12:47<00:00,  5.21it/s]\n"
     ]
    }
   ],
   "source": [
    "pred_leafs_valid = []\n",
    "for i in tqdm.tqdm(range(len(embs_valid)), total=len(embs_valid)):\n",
    "    pred_leafs_valid.append(cat_tree.choose_leaf(classifier = classifier, good_embedding=embs_valid[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0d72d101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation hF1=0.740\n"
     ]
    }
   ],
   "source": [
    "print(f'Validation hF1={cat_tree.hF1_score(valid_target, pred_leafs_valid):.3f}') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92a6f04",
   "metadata": {},
   "source": [
    "В этом ноутбуке гиперпараметры и размер выборки выбраны такими, чтобы расчёты выполнялись относительно быстро. С хорошими гиперпараметрами, на полном размере выборки, удалось получить hF1=0.85, что значительно ниже бейзлайна. Кроме того, использование CatBoost как глобального классификатора, не даёт прироста качества."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34e9534",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
