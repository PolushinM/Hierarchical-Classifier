{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f6a0f82",
   "metadata": {},
   "source": [
    "## Бейзлайн - простейший плоский классификатор на основе библиотеки FastText."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e42c57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import fasttext\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import csv\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "from HierarhicalLibrary import CategoryTree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f8b0ee",
   "metadata": {},
   "source": [
    "Подготавливаем полный, тренировочный и валидационный датасеты:\n",
    "перемешиваем данные в фрейме,\n",
    "удаляем колонки рейтинга и кол-ва отзывов,\n",
    "корректируем типы данных колонок,\n",
    "заполняем пропущенные значения,\n",
    "текст из колонок 'title', 'short_description' и 'name_value_characteristics' объединяем в колонку \"Document\", добавляем первые слова из колонки 'title', чтобы увеличить их вес (самые важные слова - в начале описания)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "293d24ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method for increasing the weight of the first words of title\n",
    "def word_pyramid(string: str, min_n_words: int, max_n_words: int) -> list:\n",
    "    result = []\n",
    "    split = string.split(' ')\n",
    "    for i in range(min_n_words, max_n_words+1):\n",
    "        result += split[:i]\n",
    "    return ' '.join(result)\n",
    "\n",
    "# Predicting labels and probabilities for list of documents \n",
    "def predict_proba(documents: list) -> tuple:\n",
    "    prediction = model.predict(documents, k=1)\n",
    "    labels_result = []\n",
    "    proba_result = []\n",
    "    for label in prediction[0]:\n",
    "        labels_result.append(int(label[0][9:]))\n",
    "    return np.array(labels_result), np.array(prediction[1])[:, 0]\n",
    "\n",
    "# Predicting on a single input\n",
    "def predict(document):\n",
    "    return int(model.predict(document)[0][0][9:])\n",
    "\n",
    "# Test data preparation\n",
    "def get_prepared_test_data(df_in: pd.DataFrame) -> pd.DataFrame:\n",
    "    df=df_in.copy()\n",
    "    df.drop(['rating', 'feedback_quantity'], axis=1, inplace=True)\n",
    "    df.title = df.title.astype('string')\n",
    "    df.short_description = df.short_description.astype('string')\n",
    "    df.fillna(value='', inplace=True)\n",
    "    df.name_value_characteristics = df.name_value_characteristics.astype('string')\n",
    "    df = df.assign(Document=[str(x) + ' ' + str(y) + ' ' + str(z) + ' ' + word_pyramid(x, 2, 3) for x, y, z in zip(df['title'], df['short_description'], df['name_value_characteristics'])])\n",
    "    df.drop(['title', 'short_description', 'name_value_characteristics'], axis=1, inplace=True)\n",
    "    df.Document = df.Document.astype('string')\n",
    "    df.Document = df.Document.apply(lambda x: ' '.join(simple_preprocess(x)))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5b13bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_data = pd.read_parquet('train.parquet')\n",
    "\n",
    "data_full = full_train_data.sample(frac=1, random_state=1).copy()\n",
    "data_full.drop(['rating', 'feedback_quantity'], axis=1, inplace=True)\n",
    "data_full.title = data_full.title.astype('string')\n",
    "data_full.short_description = data_full.short_description.astype('string')\n",
    "data_full.fillna(value='', inplace=True)\n",
    "data_full.name_value_characteristics = data_full.name_value_characteristics.astype('string')\n",
    "data_full = data_full.assign(Document=[str(x) + ' ' + str(y) + ' ' + str(z) + ' ' + word_pyramid(x, 2, 3) for x, y, z in zip(data_full['title'], data_full['short_description'], data_full['name_value_characteristics'])])\n",
    "data_full.drop(['title', 'short_description', 'name_value_characteristics'], axis=1, inplace=True)\n",
    "data_full.Document = data_full.Document.astype('string')\n",
    "\n",
    "data = data_full[:-4000].reset_index(drop=True)\n",
    "data_valid = data_full[-4000:].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0652c45c",
   "metadata": {},
   "source": [
    "Преобразуем данные в формат, принимаемый FastText."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5589f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Document = data.Document.apply(lambda x: ' '.join(simple_preprocess(x)))\n",
    "data_valid.Document = data_valid.Document.apply(lambda x: ' '.join(simple_preprocess(x)))\n",
    "\n",
    "data.category_id = data.category_id.apply(lambda x: '__label__' + str(x))\n",
    "data_valid.category_id = data_valid.category_id.apply(lambda x: '__label__' + str(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586e01ef",
   "metadata": {},
   "source": [
    "FastText принимает данные в виде текстовых файлов, поэтому сохраняем данные на диск."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67a609f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the CSV file as a text file to train/test the classifier\n",
    "data[['Document', 'category_id']].to_csv('train_fasttext.txt', \n",
    "                                          index = False, \n",
    "                                          sep = ' ',\n",
    "                                          header = None, \n",
    "                                          quoting = csv.QUOTE_NONE, \n",
    "                                          quotechar = \"\", \n",
    "                                          escapechar = \" \")\n",
    "\n",
    "data_valid[['Document', 'category_id']].to_csv('test_fasttext.txt', \n",
    "                                               index = False, \n",
    "                                               sep = ' ',\n",
    "                                               header = None, \n",
    "                                               quoting = csv.QUOTE_NONE, \n",
    "                                               quotechar = \"\", \n",
    "                                               escapechar = \" \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9f3994",
   "metadata": {},
   "source": [
    "Обучаем модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e843673b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 4M words\n",
      "Number of words:  87455\n",
      "Number of labels: 1231\n",
      "Progress: 100.0% words/sec/thread:   33844 lr:  0.000000 avg.loss:  0.335130 ETA:   0h 0m 0s  7.6% words/sec/thread:   33465 lr:  0.231058 avg.loss:  2.405015 ETA:   0h13m40s 15.8% words/sec/thread:   33706 lr:  0.210511 avg.loss:  1.441330 ETA:   0h12m22sh11m13s 25.9% words/sec/thread:   33688 lr:  0.185130 avg.loss:  0.993173 ETA:   0h10m53s 27.1% words/sec/thread:   33702 lr:  0.182219 avg.loss:  0.960179 ETA:   0h10m42s 31.1% words/sec/thread:   33754 lr:  0.172335 avg.loss:  0.863169 ETA:   0h10m 6s 32.3% words/sec/thread:   33770 lr:  0.169366 avg.loss:  0.838001 ETA:   0h 9m56s  33820 lr:  0.146919 avg.loss:  0.690758 ETA:   0h 8m36s 43.5% words/sec/thread:   33829 lr:  0.141173 avg.loss:  0.661366 ETA:   0h 8m16s words/sec/thread:   33856 lr:  0.103111 avg.loss:  0.519920 ETA:   0h 6m 2s 61.7% words/sec/thread:   33856 lr:  0.095789 avg.loss:  0.499783 ETA:   0h 5m36s 64.4% words/sec/thread:   33863 lr:  0.088918 avg.loss:  0.482467 ETA:   0h 5m12s 81.4% words/sec/thread:   33850 lr:  0.046532 avg.loss:  0.398105 ETA:   0h 2m43s 83.3% words/sec/thread:   33848 lr:  0.041645 avg.loss:  0.390271 ETA:   0h 2m26s ETA:   0h 2m 3s 0.034267 avg.loss:  0.379173 ETA:   0h 2m 0s 0.025009 avg.loss:  0.366244 ETA:   0h 1m27s 0.343164 ETA:   0h 0m24s21s\n"
     ]
    }
   ],
   "source": [
    "# Training the fastText classifier\n",
    "model = fasttext.train_supervised('train_fasttext.txt',\n",
    "                                  lr=0.25,                # learning rate [0.1]\n",
    "                                  dim=100,               # size of word vectors [100]\n",
    "                                  ws=4,                # size of the context window [5]\n",
    "                                  epoch=30,             # number of epochs [5]\n",
    "                                  neg=5,               # number of negatives sampled [5]\n",
    "                                  wordNgrams=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d528bb3a",
   "metadata": {},
   "source": [
    "Проверяем качество классификации на трейне:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe9015a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating performance on the entire train file\n",
    "_, precision, recall = model.test('train_fasttext.txt') \n",
    "leaf_F1 = (2*precision*recall) / (precision+recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5640ce10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Leaf_F1=0.9850\n"
     ]
    }
   ],
   "source": [
    "print(f'Train Leaf_F1={leaf_F1:.4f}') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eace4a2",
   "metadata": {},
   "source": [
    "Проверяем качество классификации на тестовой выборке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "383469b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating performance on the entire test file\n",
    "_, precision, recall = model.test('test_fasttext.txt')                      \n",
    "leaf_F1 = (2*precision*recall) / (precision+recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6571fbea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Leaf_F1=0.8615\n"
     ]
    }
   ],
   "source": [
    "print(f'Test Leaf_F1={leaf_F1:.4f}') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1d957e",
   "metadata": {},
   "source": [
    "При необходимости, сохраняем или загружаем модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08290af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "path = os.path.join(Path(\".\").parent, 'FastText_baseline', 'fasttext_model')\n",
    "model.save_model(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1d39287",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model\n",
    "path = os.path.join(Path(\".\").parent, 'FastText_baseline', 'fasttext_model')\n",
    "model = fasttext.load_model(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67e566c",
   "metadata": {},
   "source": [
    "Для того чтобы проверить качество иерархической классификации, инициализируем и заполняем класс дерева категорий."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4eae83ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_tree_df = pd.read_csv('categories_tree.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1da990ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_tree = CategoryTree()\n",
    "cat_tree.add_nodes_from_df(cat_tree_df, parent_id_col='parent_id', title_col='title')\n",
    "cat_tree.add_goods_from_df(data_full, category_id_col='category_id', good_id_col='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85822c3",
   "metadata": {},
   "source": [
    "Считаем метрики для train датасета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d797ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train hF1=0.9904\n",
      "Train hF1_01=0.9936\n"
     ]
    }
   ],
   "source": [
    "data_test = data[:10000].copy()\n",
    "data_test.category_id = data_test.category_id.apply(lambda text: text[9:]).astype('int')\n",
    "data_test['predicted_id'] = data_test.Document.astype('string')\n",
    "data_test.predicted_id = data_test.predicted_id.apply(lambda text: predict(text)).astype('int')\n",
    "\n",
    "test_target = data_test.category_id.tolist()\n",
    "pred_leafs = data_test.predicted_id.tolist()\n",
    "\n",
    "print(f'Train hF1={cat_tree.hF1_score(test_target, pred_leafs):.4f}') #0.9187\n",
    "print(f'Train hF1_01={cat_tree.hF1_score_01(test_target, pred_leafs):.4f}') #0.9463"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5aaa9a2",
   "metadata": {},
   "source": [
    "Предсказываем категории в тестовом сете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ae34502",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_valid_test = data_valid.copy()\n",
    "data_valid_test.category_id = data_valid_test.category_id.apply(lambda text: text[9:]).astype('int')\n",
    "data_valid_test['predicted_id'] = data_valid_test.Document.astype('string')\n",
    "data_valid_test.predicted_id = data_valid_test.predicted_id.apply(lambda text: predict(text)).astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d679ea0",
   "metadata": {},
   "source": [
    "Подготавливаем данные для расчета иерархической метрики."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c54617d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_target = data_valid_test.category_id.tolist()\n",
    "pred_leafs = data_valid_test.predicted_id.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804436cc",
   "metadata": {},
   "source": [
    "Расчет иерархической F1-меры. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3f5beef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation hF1=0.9166\n",
      "Validation hF1_01=0.9449\n"
     ]
    }
   ],
   "source": [
    "print(f'Validation hF1={cat_tree.hF1_score(test_target, pred_leafs):.4f}') #0.9187\n",
    "print(f'Validation hF1_01={cat_tree.hF1_score_01(test_target, pred_leafs):.4f}') #0.9463"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54c0d0b",
   "metadata": {},
   "source": [
    "Несмотря на простоту алгоритма, после подбора гиперпараметров получился очень хороший бейзлайн, hF1=0.91."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb1d39b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f461032",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
